{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvtYnhw5VETB"
      },
      "source": [
        "### Things to do before starting\n",
        "#### You need to name the Google Drive folder (my_batch)\n",
        "#### You need to add your zipped folder to Google Drive\n",
        "\n",
        "#### Upload fonts to your colab (Baghdad, Rakkas, Bahij)\n",
        "#### Upload the needed images to colab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dY00o75sUbRl"
      },
      "source": [
        "### Type your name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "4EFP1WIKUedv"
      },
      "outputs": [],
      "source": [
        "\n",
        "fonts = ['baghdad.ttf', 'rakkas.ttf', 'bahij.ttf']\n",
        "\n",
        "dict_names = {\n",
        "    'Omar': ['batch_1', 'Omar_batch', 'batch_1_Tashkeel_Omar.csv',\n",
        "             'batch_1_no_harakat_Omar.csv', 'batch_1_Tatweel_Omar.csv',\n",
        "             'baghdad.ttf', 'rakkas.ttf', 'bahij.ttf'],\n",
        "\n",
        "    'Gohary': ['batch_2', 'Gohary_batch', 'batch_2_Tashkeel_Gohary.csv',\n",
        "               'batch_2_no_harakat_Gohary.csv', 'batch_2_Tatweel_Gohary.csv',\n",
        "               'baghdad.ttf', 'rakkas.ttf', 'bahij.ttf'],\n",
        "\n",
        "    'Youssef': ['batch_3', 'Youssef_batch', 'batch_3_Tashkeel_Youssef.csv',\n",
        "                'batch_3_no_harakat_Youssef.csv', 'batch_3_Tatweel_Youssef.csv',\n",
        "                'baghdad.ttf', 'rakkas.ttf', 'bahij.ttf'],\n",
        "\n",
        "    'Ibrahim': ['batch_4', 'Ibrahim_batch', 'batch_4_Tashkeel_Ibrahim.csv',\n",
        "                'batch_4_no_harakat_Ibrahim.csv', 'batch_4_Tatweel_Ibrahim.csv',\n",
        "                'baghdad.ttf', 'rakkas.ttf', 'bahij.ttf'],\n",
        "\n",
        "    'Shaden': ['batch_5', 'Shaden_batch', 'batch_5_Tashkeel_Shaden.csv',\n",
        "               'batch_5_no_harakat_Shaden.csv', 'batch_5_Tatweel_Shaden.csv',\n",
        "               'baghdad.ttf', 'rakkas.ttf', 'bahij.ttf'],\n",
        "\n",
        "    'Malak': ['batch_6', 'Malak_batch', 'batch_6_rakkas_Tashkeel_Malak.csv',\n",
        "              'batch_6_no_harakat_Malak.csv', 'batch_6_Tatweel_Malak.csv',\n",
        "              'baghdad.ttf', 'rakkas.ttf', 'bahij.ttf'],\n",
        "\n",
        "    'Mayar': ['batch_7', 'Mayar_batch', 'batch_7_rakkas_Tashkeel_Mayar.csv',\n",
        "              'batch_7_no_harakat_Mayar.csv', 'batch_7_Tatweel_Mayar.csv',\n",
        "              'baghdad.ttf', 'rakkas.ttf', 'bahij.ttf'],\n",
        "\n",
        "    'Farida': ['batch_8', 'Farida_batch', 'batch_8_Tashkeel_Farida.csv',\n",
        "               'batch_8_no_harakat_Farida.csv', 'batch_8_Tatweel_Farida.csv',\n",
        "               'baghdad.ttf', 'rakkas.ttf', 'bahij.ttf'],\n",
        "}\n",
        "\n",
        "# Your name goes here\n",
        "name = ''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZtlmLHVT-pV"
      },
      "source": [
        "### Connect to Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yEUao5BVU93h",
        "outputId": "8187e8c8-f032-4561-eeea-1d41c63f3efe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pyunpack\n",
            "  Downloading pyunpack-0.3-py2.py3-none-any.whl (4.1 kB)\n",
            "Collecting easyprocess (from pyunpack)\n",
            "  Downloading EasyProcess-1.1-py3-none-any.whl (8.7 kB)\n",
            "Collecting entrypoint2 (from pyunpack)\n",
            "  Downloading entrypoint2-1.1-py2.py3-none-any.whl (9.9 kB)\n",
            "Installing collected packages: entrypoint2, easyprocess, pyunpack\n",
            "Successfully installed easyprocess-1.1 entrypoint2-1.1 pyunpack-0.3\n",
            "Collecting patool\n",
            "  Downloading patool-2.2.0-py2.py3-none-any.whl (96 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.0/96.0 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: patool\n",
            "Successfully installed patool-2.2.0\n"
          ]
        }
      ],
      "source": [
        "!pip3 install pyunpack\n",
        "!pip3 install patool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "udp3TBPGUUUg",
        "outputId": "24b6ca28-eacb-4de8-c9bd-f9b18b5d8b87"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XPa2citbbaec"
      },
      "source": [
        "#### Unzip your folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Qrww7Rt3VAPD"
      },
      "outputs": [],
      "source": [
        "from pyunpack import Archive\n",
        "Archive(f'./gdrive/MyDrive/my_batch/{dict_names[name][1]}.zip').extractall(\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aFJ2IZsdUVG1"
      },
      "source": [
        "### Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Cgkrjlt2zq-",
        "outputId": "e124b2a3-528e-4575-f5df-97299a70db39"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting py7zr\n",
            "  Downloading py7zr-0.21.0-py3-none-any.whl (67 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/67.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m61.4/67.6 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m61.4/67.6 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.6/67.6 kB\u001b[0m \u001b[31m811.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting texttable (from py7zr)\n",
            "  Downloading texttable-1.7.0-py2.py3-none-any.whl (10 kB)\n",
            "Collecting pycryptodomex>=3.16.0 (from py7zr)\n",
            "  Downloading pycryptodomex-3.20.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyzstd>=0.15.9 (from py7zr)\n",
            "  Downloading pyzstd-0.15.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (411 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m411.2/411.2 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyppmd<1.2.0,>=1.1.0 (from py7zr)\n",
            "  Downloading pyppmd-1.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.9/138.9 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pybcj<1.1.0,>=1.0.0 (from py7zr)\n",
            "  Downloading pybcj-1.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.7/49.7 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multivolumefile>=0.2.3 (from py7zr)\n",
            "  Downloading multivolumefile-0.2.3-py3-none-any.whl (17 kB)\n",
            "Collecting inflate64<1.1.0,>=1.0.0 (from py7zr)\n",
            "  Downloading inflate64-1.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (93 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.1/93.1 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting brotli>=1.1.0 (from py7zr)\n",
            "  Downloading Brotli-1.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from py7zr) (5.9.5)\n",
            "Installing collected packages: texttable, brotli, pyzstd, pyppmd, pycryptodomex, pybcj, multivolumefile, inflate64, py7zr\n",
            "Successfully installed brotli-1.1.0 inflate64-1.0.0 multivolumefile-0.2.3 py7zr-0.21.0 pybcj-1.0.2 pycryptodomex-3.20.0 pyppmd-1.1.0 pyzstd-0.15.10 texttable-1.7.0\n",
            "Cloning into 'TextRecognitionDataGenerator'...\n",
            "remote: Enumerating objects: 1585, done.\u001b[K\n",
            "remote: Total 1585 (delta 0), reused 0 (delta 0), pack-reused 1585\u001b[K\n",
            "Receiving objects: 100% (1585/1585), 157.02 MiB | 20.42 MiB/s, done.\n",
            "Resolving deltas: 100% (638/638), done.\n",
            "Updating files: 100% (633/633), done.\n",
            "Collecting git+https://github.com/mohataher/TextRecognitionDataGenerator.git\n",
            "  Cloning https://github.com/mohataher/TextRecognitionDataGenerator.git to /tmp/pip-req-build-bzw94vt7\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/mohataher/TextRecognitionDataGenerator.git /tmp/pip-req-build-bzw94vt7\n",
            "  Resolved https://github.com/mohataher/TextRecognitionDataGenerator.git to commit fc57f204be03bc5c09143c8d0ff7a6f8bf02eeda\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pillow>=7.0.0 in /usr/local/lib/python3.10/dist-packages (from trdg==1.8.0) (9.4.0)\n",
            "Requirement already satisfied: requests>=2.20.0 in /usr/local/lib/python3.10/dist-packages (from trdg==1.8.0) (2.31.0)\n",
            "Requirement already satisfied: opencv-python>=4.2.0.32 in /usr/local/lib/python3.10/dist-packages (from trdg==1.8.0) (4.8.0.76)\n",
            "Requirement already satisfied: tqdm>=4.23.0 in /usr/local/lib/python3.10/dist-packages (from trdg==1.8.0) (4.66.2)\n",
            "Collecting wikipedia>=1.4.0 (from trdg==1.8.0)\n",
            "  Downloading wikipedia-1.4.0.tar.gz (27 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting diffimg==0.2.3 (from trdg==1.8.0)\n",
            "  Downloading diffimg-0.2.3.tar.gz (4.1 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting arabic-reshaper==2.1.3 (from trdg==1.8.0)\n",
            "  Downloading arabic_reshaper-2.1.3-py3-none-any.whl (20 kB)\n",
            "Collecting python-bidi==0.4.2 (from trdg==1.8.0)\n",
            "  Downloading python_bidi-0.4.2-py2.py3-none-any.whl (30 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from arabic-reshaper==2.1.3->trdg==1.8.0) (0.18.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from arabic-reshaper==2.1.3->trdg==1.8.0) (67.7.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from python-bidi==0.4.2->trdg==1.8.0) (1.16.0)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python>=4.2.0.32->trdg==1.8.0) (1.25.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20.0->trdg==1.8.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20.0->trdg==1.8.0) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20.0->trdg==1.8.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20.0->trdg==1.8.0) (2024.2.2)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from wikipedia>=1.4.0->trdg==1.8.0) (4.12.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->wikipedia>=1.4.0->trdg==1.8.0) (2.5)\n",
            "\u001b[33mWARNING: The candidate selected for download or install is a yanked version: 'arabic-reshaper' candidate (version 2.1.3 at https://files.pythonhosted.org/packages/47/27/7b9b824f5342d8ee180027333f2e15842ea36f5bc2d3d24a4e6bb31fb596/arabic_reshaper-2.1.3-py3-none-any.whl (from https://pypi.org/simple/arabic-reshaper/))\n",
            "Reason for being yanked: Doesn't work with Python 2\u001b[0m\u001b[33m\n",
            "\u001b[0mBuilding wheels for collected packages: trdg, diffimg, wikipedia\n",
            "  Building wheel for trdg (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for trdg: filename=trdg-1.8.0-py3-none-any.whl size=99407789 sha256=00e3fe27a6aa4074d18ca270c9cadcbea025e3c28e291d040a038ef3cf698936\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-sbpoegvz/wheels/c2/ee/bf/eb996ce39dcd1afc0561697f435b59a940ebaabb5146772a64\n",
            "  Building wheel for diffimg (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for diffimg: filename=diffimg-0.2.3-py3-none-any.whl size=4019 sha256=bb37adbd92f9dcd31b55e2cd5fb5574a538dcf149b039a4757a9841f6d138219\n",
            "  Stored in directory: /root/.cache/pip/wheels/90/57/92/d4259a51f20cf92a473b567a009674e3390852b7fab19be6dc\n",
            "  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wikipedia: filename=wikipedia-1.4.0-py3-none-any.whl size=11680 sha256=9d48db79ab88d86175635900aebad841967ef3d13ae3dcf7d5980fb75dd4012f\n",
            "  Stored in directory: /root/.cache/pip/wheels/5e/b6/c5/93f3dec388ae76edc830cb42901bb0232504dfc0df02fc50de\n",
            "Successfully built trdg diffimg wikipedia\n",
            "Installing collected packages: python-bidi, diffimg, arabic-reshaper, wikipedia, trdg\n",
            "Successfully installed arabic-reshaper-2.1.3 diffimg-0.2.3 python-bidi-0.4.2 trdg-1.8.0 wikipedia-1.4.0\n"
          ]
        }
      ],
      "source": [
        "!pip install py7zr\n",
        "!git clone https://github.com/mohataher/TextRecognitionDataGenerator.git\n",
        "!pip install git+https://github.com/mohataher/TextRecognitionDataGenerator.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "dLfc3LzsOOj3"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import shutil\n",
        "import tempfile\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from copy import copy\n",
        "from PIL import Image\n",
        "from py7zr import SevenZipFile\n",
        "from skimage.util import random_noise\n",
        "from trdg.generators import GeneratorFromStrings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kXNw6tH4bgbF"
      },
      "source": [
        "### Create needed folders. Move images and fonts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "4uvKjlAQbij7",
        "outputId": "7b3d283a-364a-4408-ef23-afc61297e0b2"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'./fonts/bahij.ttf'"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create the Output directory\n",
        "os.mkdir('test_batch')\n",
        "os.mkdir(f'{name}_generated_batch')\n",
        "os.mkdir('./test_batch/tashkeel_batch')\n",
        "os.mkdir('./test_batch/no_harakat_batch')\n",
        "os.mkdir('./test_batch/tatweel_batch')\n",
        "\n",
        "# Create directory for each font\n",
        "# inside each harakat directory\n",
        "for font in fonts:\n",
        "  font_name = font.split('.')[0]\n",
        "  os.mkdir(f'./test_batch/tashkeel_batch/{font_name}')\n",
        "  os.mkdir(f'./test_batch/no_harakat_batch/{font_name}')\n",
        "  os.mkdir(f'./test_batch/tatweel_batch/{font_name}')\n",
        "\n",
        "# Create directory for backgrounds\n",
        "os.mkdir('./images')\n",
        "os.mkdir('./images/wm_folder')\n",
        "os.mkdir('./images/yellow_folder')\n",
        "\n",
        "# Create directory for fonts\n",
        "os.mkdir('./fonts')\n",
        "\n",
        "# Move backgrounds to images directory\n",
        "shutil.move(\"wm_image.jpeg\", \"./images/wm_folder/wm_image.jpeg\")\n",
        "shutil.move(\"yellow_background.jpeg\", \"./images/yellow_folder/yellow_background.jpeg\")\n",
        "\n",
        "# Move fonts to fonts directory\n",
        "shutil.move('baghdad.ttf', './fonts/baghdad.ttf')\n",
        "shutil.move('rakkas.ttf', './fonts/rakkas.ttf')\n",
        "shutil.move('bahij.ttf', './fonts/bahij.ttf')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5RLX3aDu_wO"
      },
      "source": [
        "### Run the functions\n",
        "#### Do not forget to collapse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ZHqM27Diu-NV"
      },
      "outputs": [],
      "source": [
        "def split_into_n_batches(batch, n):\n",
        "    shuffled_batch = copy(batch)\n",
        "    np.random.shuffle(shuffled_batch)\n",
        "    sublist_size = len(shuffled_batch) // n\n",
        "    remainder = len(shuffled_batch) % n\n",
        "\n",
        "    sublists = [shuffled_batch[i * sublist_size + min(i, remainder):(i + 1) * sublist_size + min(i + 1, remainder)] for i in range(n)]\n",
        "\n",
        "    return sublists\n",
        "\n",
        "\n",
        "def split_into_baghdad_rakkas_bahij(batch):\n",
        "  shuffled_batch = copy(batch)\n",
        "  np.random.shuffle(shuffled_batch)\n",
        "  split_index = int(len(shuffled_batch) * 0.7)\n",
        "\n",
        "  # Split into 70% Baghdad and Rakkas fonts and 30% Bahij Font\n",
        "  baghdad_rakkas_batch = shuffled_batch[:split_index]\n",
        "  bahij_batch = shuffled_batch[split_index:]\n",
        "\n",
        "  # Split baghdad_rakkas_batch equally\n",
        "  baghdad_batch, rakkas_batch = split_into_n_batches(baghdad_rakkas_batch, 2)\n",
        "\n",
        "  return baghdad_batch, rakkas_batch, bahij_batch\n",
        "\n",
        "\n",
        "def split_into_plain_image(batch):\n",
        "  shuffled_batch = copy(batch)\n",
        "  np.random.shuffle(shuffled_batch)\n",
        "\n",
        "  # Split the input batch into plain white batch and image batch\n",
        "  split_index = int(len(shuffled_batch) * 0.8)\n",
        "  plain_white_batch = shuffled_batch[:split_index]\n",
        "  image_batch = shuffled_batch[split_index:]\n",
        "\n",
        "  # Split the image batch into watermark batch and yellow batch\n",
        "  image_wm_batch, image_yellow_batch = split_into_n_batches(image_batch, 2)\n",
        "\n",
        "  return plain_white_batch, image_wm_batch, image_yellow_batch\n",
        "\n",
        "\n",
        "def create_generators_plain_image(plain_white_batch : list[str], image_wm_batch : list[str],\n",
        "                                  image_yellow_batch : list[str], font_type : str, harakat_type : str):\n",
        "  result = []\n",
        "  font_name = font_type.split('.')[0]\n",
        "  batches_details = [(plain_white_batch, len(plain_white_batch), 1, None, f'{harakat_type}_{font_name}_no_noise_plain'),\n",
        "                     (image_wm_batch, len(image_wm_batch), 3, './images/wm_folder', f'{harakat_type}_{font_name}_no_noise_wm'),\n",
        "                     (image_yellow_batch, len(image_yellow_batch), 3, './images/yellow_folder', f'{harakat_type}_{font_name}_no_noise_yellow')\n",
        "                    ]\n",
        "\n",
        "  for details in batches_details:\n",
        "    if details[3] == None:\n",
        "      generator = GeneratorFromStrings(details[0], count=details[1], background_type=details[2],\n",
        "                                       size=75, fit=True, rtl=True, fonts=[f'./fonts/{font_type}']\n",
        "                                      )\n",
        "\n",
        "    else:\n",
        "      generator = GeneratorFromStrings(details[0], count=details[1], background_type=details[2],\n",
        "                                       image_dir=details[3], size=75, fit=True, rtl=True, fonts=[f'./fonts/{font_type}']\n",
        "                                      )\n",
        "\n",
        "    result.append((details[4], generator))\n",
        "\n",
        "  return result\n",
        "\n",
        "\n",
        "def create_generators_plain_gaussian_img(plain_batch : list[str], gaussian_batch : list[str],\n",
        "                                         image_wm_batch : list[str], image_yellow_batch : list[str],\n",
        "                                         font_type : str, harakat_type : str, batch_type : int):\n",
        "  # (list, list_length, background_type, image_dir, skew_angle, random_skew, blur, random_blur, distorsion_type, batch_name)\n",
        "  result = []\n",
        "  font_name = font_type.split('.')[0]\n",
        "  batches_details = [\n",
        "      [(plain_batch, len(plain_batch), 1, None, 3, True, 0, False, 0, f'{harakat_type}_{font_name}_noise_skew_plain'), # Plain\n",
        "       (gaussian_batch, len(gaussian_batch), 1, None, 3, True, 0, False, 0, f'{harakat_type}_{font_name}_noise_skew_gaussian'), # Gaussian\n",
        "       (image_wm_batch, len(image_wm_batch), 3, './images/wm_folder', 3, True, 0, False, 0, f'{harakat_type}_{font_name}_noise_skew_wm'), # Images\n",
        "       (image_yellow_batch, len(image_yellow_batch), 3, './images/yellow_folder', 3, True, 0, False, 0, f'{harakat_type}_{font_name}_noise_skew_yellow')\n",
        "      ], # Skew\n",
        "      [(plain_batch, len(plain_batch), 1, None, 0, False, 0.8, True, 0, f'{harakat_type}_{font_name}_noise_blur_plain'), # Plain\n",
        "       (gaussian_batch, len(gaussian_batch), 1, None, 0, False, 0.8, True, 0, f'{harakat_type}_{font_name}_noise_blur_gaussian'), # Gaussian\n",
        "       (image_wm_batch, len(image_wm_batch), 3, './images/wm_folder', 0, False, 0.8, True, 0, f'{harakat_type}_{font_name}_noise_blur_wm'), # Images\n",
        "       (image_yellow_batch, len(image_yellow_batch), 3, './images/yellow_folder', 0, False, 0.8, True, 0, f'{harakat_type}_{font_name}_noise_blur_yellow')\n",
        "      ], # Blur\n",
        "      [(plain_batch, len(plain_batch), 1, None, 0, False, 0, False, 3, f'{harakat_type}_{font_name}_noise_distorsion_plain'), # Plain\n",
        "       (gaussian_batch, len(gaussian_batch), 1, None, 0, False, 0, False, 3, f'{harakat_type}_{font_name}_noise_distorsion_gaussian'), # Gaussian\n",
        "       (image_wm_batch, len(image_wm_batch), 3, './images/wm_folder', 0, False, 0, False, 3, f'{harakat_type}_{font_name}_noise_distorsion_wm'), # Images\n",
        "       (image_yellow_batch, len(image_yellow_batch), 3, './images/yellow_folder', 0, False, 0, False, 3, f'{harakat_type}_{font_name}_noise_distorsion_yellow')\n",
        "      ] # Distorsion\n",
        "  ]\n",
        "\n",
        "  for details in batches_details[batch_type]:\n",
        "    if details[3] == None:\n",
        "      generator = GeneratorFromStrings(details[0], count=details[1], background_type=details[2],\n",
        "                                       skewing_angle=details[4], random_skew=details[5], blur=details[6],\n",
        "                                       random_blur=details[7], distorsion_type=details[8],\n",
        "                                       size=75, fit=True, rtl=True, fonts=[f'./fonts/{font_type}']\n",
        "                                      )\n",
        "      \n",
        "    else:\n",
        "      generator = GeneratorFromStrings(details[0], count=details[1], background_type=details[2],\n",
        "                                       image_dir=details[3], skewing_angle=details[4], random_skew=details[5],\n",
        "                                       blur=details[6], random_blur=details[7], distorsion_type=details[8],\n",
        "                                       size=75, fit=True, rtl=True, fonts=[f'./fonts/{font_type}']\n",
        "                                      )\n",
        "\n",
        "    result.append((details[9], generator))\n",
        "\n",
        "  return result\n",
        "\n",
        "\n",
        "def generate_font(batch : list[str], font_type : str, harakat_type : str):\n",
        "  # This list will contain the batch name and the batch generator\n",
        "  font_generators_list = []\n",
        "\n",
        "  # Split the font batch into two batches.\n",
        "  # First batch with no noises and second batch with noises\n",
        "  font_with_no_noises, font_with_noises = split_into_n_batches(batch, 2)\n",
        "\n",
        "  # Split the font batch with no noises\n",
        "  # into palin white batch, watermark batch and yellow background batch\n",
        "  font_plain_batch, font_image_wm_batch, font_image_yellow_batch = split_into_plain_image(font_with_no_noises)\n",
        "\n",
        "  # Generate images for palin white batch,\n",
        "  # watermark batch and yellow background batch\n",
        "  # and put them into font_generators_list\n",
        "  font_generators_list.extend(create_generators_plain_image(font_plain_batch, font_image_wm_batch, font_image_yellow_batch,\n",
        "                                                            font_type, harakat_type))\n",
        "\n",
        "  # Split the font batch with noises\n",
        "  # into skew batch, blur batch and distorsion batch\n",
        "  for i, splitted_batch in enumerate(split_into_n_batches(font_with_noises, 3)):\n",
        "    # Split the splitted batch into\n",
        "    # plain batch, gaussiaan batch and image batch\n",
        "    splitted_plain_batch, splitted_gaussian_batch, splitted_image_batch = split_into_n_batches(splitted_batch, 3)\n",
        "\n",
        "    # Split the splitted image batch into\n",
        "    # watermark batch and yellow background batch\n",
        "    splitted_image_wm_batch, splitted_image_yellow_batch = split_into_n_batches(splitted_image_batch, 2)\n",
        "\n",
        "    font_generators_list.extend(create_generators_plain_gaussian_img(splitted_plain_batch, splitted_gaussian_batch,\n",
        "                                                                     splitted_image_wm_batch, splitted_image_yellow_batch,\n",
        "                                                                     font_type, harakat_type, i))\n",
        "\n",
        "  return font_generators_list\n",
        "\n",
        "\n",
        "def generate_gaussian_batch(batch_name, generator, is_test = False) -> None:\n",
        "  splitted_name = batch_name.split('_')\n",
        "  path = f\"./test_batch/{splitted_name[0]}_batch/{splitted_name[1]}/{batch_name}_{name}\" if is_test == True else f\"./{name}_generated_batch/{batch_name}_{name}\"\n",
        "\n",
        "  for i, (img, lbl) in enumerate(generator):\n",
        "    gauss_img = random_noise(np.array(img), mode='gaussian', clip=True)\n",
        "    noise_im = np.array(255 * gauss_img, dtype='uint8')\n",
        "    pil_image = Image.fromarray(np.array(noise_im))\n",
        "\n",
        "    image_info = pil_image.info.copy()\n",
        "    image_info['dpi'] = (300, 300)\n",
        "    pil_image.save(f\"{path}_{i+1}.tif\", **image_info)\n",
        "    with open(f\"{path}_{i+1}.gt.txt\", 'w') as f:\n",
        "      f.write(lbl)\n",
        "\n",
        "\n",
        "def generate_batch(generators_list : list[tuple], is_test : bool = False) -> None:\n",
        "  for batch_name, generator in generators_list:\n",
        "    if 'gaussian' in batch_name:\n",
        "      generate_gaussian_batch(batch_name, generator, is_test)\n",
        "      continue\n",
        "\n",
        "    splitted_name = batch_name.split('_')\n",
        "    path = f\"./test_batch/{splitted_name[0]}_batch/{splitted_name[1]}/{batch_name}_{name}\" if is_test == True else f\"./{name}_generated_batch/{batch_name}_{name}\"\n",
        "    for i, (img, lbl) in enumerate(generator):\n",
        "      image_info = img.info.copy()\n",
        "      image_info['dpi'] = (300, 300)\n",
        "      img.save(f\"{path}_{i+1}.tif\", **image_info)\n",
        "      with open(f\"{path}_{i+1}.gt.txt\", 'w') as f:\n",
        "        f.write(lbl)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sbjlLkWVaDm0"
      },
      "source": [
        "### Read your dataframes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "fXbCuq3YX64c"
      },
      "outputs": [],
      "source": [
        "tashkeel_df = pd.read_csv(f'./{dict_names[name][1]}/{dict_names[name][2]}')\n",
        "no_harakat_df = pd.read_csv(f'./{dict_names[name][1]}/{dict_names[name][3]}')\n",
        "tatweel_df = pd.read_csv(f'./{dict_names[name][1]}/{dict_names[name][4]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vliTzm0hhi5K",
        "outputId": "2734971e-bb09-474c-c7e9-687ca2616983"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(62881, 80087, 1197)"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tashkeel_df.shape[0], no_harakat_df.shape[0], tatweel_df.shape[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XgzZR02Ma22X"
      },
      "source": [
        "### Generate Images and files for tashkeel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sodLim0ahrkQ"
      },
      "source": [
        "#### Split the dataframe into 3 batches\n",
        "#### for fonts baghdad, rakkas and bahij"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Lzs5Z8Cba8pm"
      },
      "outputs": [],
      "source": [
        "tashkeel_baghdad_batch, tashkeel_rakkas_batch, tashkeel_bahij_batch = split_into_baghdad_rakkas_bahij(tashkeel_df.text.tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tt2-XED4ujak",
        "outputId": "0d6baac3-73e6-4cc8-9aa6-6bfa03992c2f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "62881\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(22008, 22008, 18865)"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(tashkeel_df.shape[0])\n",
        "len(tashkeel_baghdad_batch), len(tashkeel_rakkas_batch), len(tashkeel_bahij_batch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GUXRd5s55u9f"
      },
      "source": [
        "#### Generate images and text files for each font"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EfWdZh0bQOAF"
      },
      "outputs": [],
      "source": [
        "tashkeel_baghdad_generators_list = generate_font(tashkeel_baghdad_batch, fonts[0], 'tashkeel')\n",
        "generate_batch(tashkeel_baghdad_generators_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xsvetklAQOuD"
      },
      "outputs": [],
      "source": [
        "tashkeel_rakkas_generators_list = generate_font(tashkeel_rakkas_batch, fonts[1], 'tashkeel')\n",
        "generate_batch(tashkeel_rakkas_generators_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SBnsOCvS5uf3"
      },
      "outputs": [],
      "source": [
        "tashkeel_bahij_generators_list = generate_font(tashkeel_bahij_batch, fonts[2], 'tashkeel')\n",
        "generate_batch(tashkeel_bahij_generators_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0nO5uEOOa9yF"
      },
      "source": [
        "### Generate Images and files for no harakat"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CBUPlAoIYfqc"
      },
      "source": [
        "#### Split the dataframe into 3 batches\n",
        "#### for fonts baghdad, rakkas and bahij"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WSdC4CQUbHmG"
      },
      "outputs": [],
      "source": [
        "no_harakat_baghdad_batch, no_harakat_rakkas_batch, no_harakat_bahij_batch = split_into_baghdad_rakkas_bahij(no_harakat_df.text.tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s0rMo5zNZEzr",
        "outputId": "dad6fda0-6818-4674-b754-b07bacb1d611"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "80087\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(28030, 28030, 24027)"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(no_harakat_df.shape[0])\n",
        "len(no_harakat_baghdad_batch), len(no_harakat_rakkas_batch), len(no_harakat_bahij_batch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_LMe4_fZLGq"
      },
      "source": [
        "#### Generate images and text files for each font"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "55X8RSB1ZUwg"
      },
      "outputs": [],
      "source": [
        "no_harakat_baghdad_generators_list = generate_font(no_harakat_baghdad_batch, fonts[0], 'no_harakat')\n",
        "generate_batch(no_harakat_baghdad_generators_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QaBBOmWnZVl2"
      },
      "outputs": [],
      "source": [
        "no_harakat_rakkas_generators_list = generate_font(no_harakat_rakkas_batch, fonts[1], 'no_harakat')\n",
        "generate_batch(no_harakat_rakkas_generators_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "64aIiAVLZV7N"
      },
      "outputs": [],
      "source": [
        "no_harakat_bahij_generators_list = generate_font(no_harakat_bahij_batch, fonts[2], 'no_harakat')\n",
        "generate_batch(no_harakat_bahij_generators_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zSAIMPeebETe"
      },
      "source": [
        "### Generate Images and files for tatweel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HBmhmUs6dNAY"
      },
      "source": [
        "#### Split the dataframe into 3 batches\n",
        "#### for fonts baghdad, rakkas and bahij"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s817xqw8bIH4"
      },
      "outputs": [],
      "source": [
        "tatweel_baghdad_batch, tatweel_rakkas_batch, tatweel_bahij_batch = split_into_baghdad_rakkas_bahij(tatweel_df.text.tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oH90NLjvdn4T"
      },
      "outputs": [],
      "source": [
        "print(tatweel_df.shape[0])\n",
        "len(tatweel_baghdad_batch), len(tatweel_rakkas_batch), len(tatweel_bahij_batch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8JoZOYyOdsCt"
      },
      "source": [
        "#### Generate images and text files for each font"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7egnDblldsph"
      },
      "outputs": [],
      "source": [
        "tatweel_baghdad_generators_list = generate_font(tatweel_baghdad_batch, fonts[0], 'tatweel')\n",
        "generate_batch(tatweel_baghdad_generators_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fE3MRFCbdxXD"
      },
      "outputs": [],
      "source": [
        "tatweel_rakkas_generators_list = generate_font(tatweel_rakkas_batch, fonts[1], 'tatweel')\n",
        "generate_batch(tatweel_rakkas_generators_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TKdajI4Gd1Zp"
      },
      "outputs": [],
      "source": [
        "tatweel_bahij_generators_list = generate_font(tatweel_bahij_batch, fonts[2], 'tatweel')\n",
        "generate_batch(tatweel_bahij_generators_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YNDZgco7d8sR"
      },
      "source": [
        "### Compress the file and move it to your Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "MB1FRWcTePyF"
      },
      "outputs": [],
      "source": [
        "folder_to_compress = f\"./{name}_generated_batch\"\n",
        "output_archive = f\"./gdrive/MyDrive/my_batch/{name}_generated_batch.7z\"\n",
        "\n",
        "with SevenZipFile(output_archive, 'w') as archive:\n",
        "        archive.writeall(folder_to_compress)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
