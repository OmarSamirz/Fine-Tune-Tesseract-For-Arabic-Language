{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1 = load_dataset(\"dru-ac/ArTopicDS-Books\") \n",
    "# dataset2 = load_dataset(\"premio-ai/TheArabicPile_Books\")\n",
    "dataset3 = load_dataset(\"Yasbok/Alpaca_arabic_instruct\")\n",
    "dataset4 = load_dataset(\"M-A-D/Mixed-Arabic-Datasets-Repo\", 'Ara--Ali-C137--Hindawi-Books-dataset')\n",
    "dataset5 = load_dataset(\"M-A-D/Mixed-Arabic-Datasets-Repo\", 'Ara--J-Mourad--MNAD.v1')\n",
    "dataset6 = load_dataset(\"2A2I/Arabic-OpenHermes-2.5\")\n",
    "dataset7 = load_dataset(\"MBZUAI/ArabicMMLU\", trust_remote_code=True)\n",
    "dataset8 = load_dataset(\"M-A-D/Mixed-Arabic-Datasets-Repo\", 'Ara--mustapha--QuranExe')\n",
    "dataset9 = load_dataset(\"Nuwaisir/Quran_speech_recognition_kaggle\")\n",
    "\n",
    "# you can use any of the following config names as a second argument:\n",
    "\"Alittihad\", \"Almasryalyoum\", \"Almustaqbal\", \"Alqabas\", \n",
    "\"Echoroukonline\", \"Ryiadh\", \"Sabanews\", \"SaudiYoum\", \n",
    "\"Techreen\", \"Youm7\"\n",
    "# dataset8 = load_dataset(\"arabic_billion_words\", \"Almasryalyoum\", trust_remote_code=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert datasets type to pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1.set_format(type='pandas')\n",
    "# dataset2.set_format(type='pandas')\n",
    "dataset3.set_format(type='pandas')\n",
    "dataset4.set_format(type='pandas')\n",
    "dataset5.set_format(type='pandas')\n",
    "dataset6.set_format(type='pandas')\n",
    "dataset7.set_format(type='pandas')\n",
    "dataset8.set_format(type='pandas')\n",
    "dataset9.set_format(type='pandas')\n",
    "\n",
    "df1 = dataset1['train'][:]\n",
    "# df2 = dataset2['train'][:]\n",
    "df3 = dataset3['train'][:]\n",
    "df4 = dataset4['train'][:]\n",
    "df5 = dataset5['train'][:]\n",
    "df6 = dataset6['train'][:]\n",
    "df7 = dataset7['test'][:]\n",
    "df8 = dataset8['train'][:]\n",
    "df9 = dataset9['train'][:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Each dataset number of rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df1.shape[0], df3.shape[0], df4.shape[0], df5.shape[0], df6.shape[0], df7.shape[0], df8.shape[0], df9.shape[0])\n",
    "print(f\"Total number of rows without df6: {df1.shape[0] + df3.shape[0] + df4.shape[0] + df5.shape[0] + df7.shape[0] + df8.shape[0] + df9.shape[0]}\")\n",
    "print(f\"Total number of rows with df6: {df1.shape[0] + df3.shape[0] + df4.shape[0] + df5.shape[0] + df6.shape[0] + df7.shape[0] + df8.shape[0] + df9.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Each dataset columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['text', 'en_topic'], dtype='object')\n",
      "Index(['instruction', 'input', 'output'], dtype='object')\n",
      "Index(['BookLink', 'BookName', 'AuthorName', 'AboutBook', 'ChapterLink',\n",
      "       'ChapterName', 'ChapterText', 'AboutAuthor'],\n",
      "      dtype='object')\n",
      "Index(['Title', 'Body', 'Category'], dtype='object')\n",
      "Index(['title', 'category', 'system_prompt', 'topic', 'avatarUrl', 'model',\n",
      "       'hash', 'skip_prompt_formatting', 'custom_instruction', 'idx',\n",
      "       'language', 'views', 'source', 'model_name', 'id', 'user', 'gpt',\n",
      "       'conversations'],\n",
      "      dtype='object')\n",
      "Index(['ID', 'Source', 'Country', 'Group', 'Subject', 'Level', 'Question',\n",
      "       'Context', 'Answer Key', 'Option 1', 'Option 2', 'Option 3', 'Option 4',\n",
      "       'Option 5', 'is_few_shot'],\n",
      "      dtype='object')\n",
      "Index(['text', 'resource_name', 'verses_keys'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df1.columns, df3.columns, df4.columns, df5.columns, df6.columns, df7.columns, df8.columns, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.drop('en_topic', axis=1, inplace=True)\n",
    "df4.drop(['BookLink', 'AuthorName', 'ChapterLink'], axis=1, inplace=True)\n",
    "df5.drop('Category', axis=1, inplace=True)\n",
    "df6 = df6['user']\n",
    "\n",
    "df7['final_text'] = df7['Question'] + ' ' + df7['Option 1']  + ' ' + df7['Option 2']  + ' ' + df7['Option 3'] + ' ' + df7['Option 4']\n",
    "df7 = df7['final_text']\n",
    "df8 = df8['text']\n",
    "df9 = df9['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save dataset as CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv('downloaded_datasets/ArTopicDS-Books.csv', encoding='utf-8-sig', index=False)\n",
    "df3.to_csv('downloaded_datasets/Alpaca_arabic_instruct.csv', encoding='utf-8-sig', index=False)\n",
    "df4.to_csv('downloaded_datasets/Mixed-Arabic-Datasets-Repo-Ara--Ali-C137--Hindawi-Books-dataset.csv', encoding='utf-8-sig', index=False) # Too big to save every time\n",
    "df5.to_csv('downloaded_datasets/Mixed-Arabic-Datasets-Repo-Ara--J-Mourad--MNAD.v1.csv', encoding='utf-8-sig', index=False) # Too big to save every time\n",
    "df6.to_csv('downloaded_datasets/Arabic-OpenHermes-2.5.csv', encoding='utf-8-sig', index=False)\n",
    "df7.to_csv('downloaded_datasets/ArabicMMLU.csv', encoding='utf-8-sig', index=False)\n",
    "df8.to_csv('downloaded_datasets/Mixed-Arabic-Datasets-Repo-Ara--mustapha--QuranExe.csv', encoding='utf-8-sig', index=False)\n",
    "df9.to_csv('downloaded_datasets/Quran_speech_recognition_kaggle.csv', encoding='utf-8-sig', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
